======================================================================
使用新仿真器 (HDF5) 数据训练损伤检测模型
======================================================================

[步骤1] 加载仿真数据...
[Optimization] 发现 15 个数据分片，正在构建索引...
[Optimization] 索引构建完成，总样本数: 9000

✓ 样本数 (9000) 足够进行训练

[步骤2] 初始化检测系统...
  ✓ 设备: cpu
  ✓ 类别数: 2
  ✓ 模型参数量: 3,241,826

[步骤3] 划分数据集 (适配分片结构)...
  ✓ 训练集场景数: 1800, 样本数: 5400
  ✓ 验证集场景数: 600, 样本数: 1800
  ✓ 测试集场景数: 600, 样本数: 1800
[Optimization] 发现 15 个数据分片，正在构建索引...
[Optimization] 索引构建完成，总样本数: 9000
[Optimization] 发现 15 个数据分片，正在构建索引...
[Optimization] 索引构建完成，总样本数: 9000
[Optimization] 发现 15 个数据分片，正在构建索引...
[Optimization] 索引构建完成，总样本数: 9000

[步骤4] 创建 DataLoader...

[步骤5] 训练模型...
  训练轮数: 30
  学习率: 0.001
  早停耐心值: 6
Batch 20/169 Loss: 0.6346 TS Grad: 2.2471 Img Grad: 1.1985 Ratio: 0.53
Batch 40/169 Loss: 0.6306 TS Grad: 3.3084 Img Grad: 1.0892 Ratio: 0.33
Batch 60/169 Loss: 0.6856 TS Grad: 2.2376 Img Grad: 1.1154 Ratio: 0.50
Batch 80/169 Loss: 0.7009 TS Grad: 2.1591 Img Grad: 1.1929 Ratio: 0.55
Batch 100/169 Loss: 0.6299 TS Grad: 2.2136 Img Grad: 0.7289 Ratio: 0.33
Batch 120/169 Loss: 0.7245 TS Grad: 2.7128 Img Grad: 0.6576 Ratio: 0.24
Batch 140/169 Loss: 0.7153 TS Grad: 2.9319 Img Grad: 0.8780 Ratio: 0.30
Batch 160/169 Loss: 0.5779 TS Grad: 1.9586 Img Grad: 0.5754 Ratio: 0.29

Epoch [1/30], Train Loss: 0.6676, Acc: 60.31%, Val Loss: 2.2382, Acc: 61.94%

Batch 20/169 Loss: 0.6326 TS Grad: 4.4006 Img Grad: 0.5887 Ratio: 0.13
Batch 40/169 Loss: 0.6649 TS Grad: 3.5452 Img Grad: 0.4198 Ratio: 0.12
Batch 60/169 Loss: 0.5581 TS Grad: 3.8600 Img Grad: 0.4132 Ratio: 0.11
Batch 80/169 Loss: 0.6354 TS Grad: 3.7367 Img Grad: 1.5170 Ratio: 0.41
Batch 100/169 Loss: 0.5951 TS Grad: 3.5438 Img Grad: 0.0982 Ratio: 0.03
Batch 120/169 Loss: 0.7485 TS Grad: 3.7371 Img Grad: 0.4847 Ratio: 0.13
Batch 140/169 Loss: 0.5206 TS Grad: 2.4533 Img Grad: 0.1770 Ratio: 0.07
Batch 160/169 Loss: 0.4808 TS Grad: 2.5179 Img Grad: 0.8022 Ratio: 0.32

Epoch [2/30], Train Loss: 0.5988, Acc: 67.46%, Val Loss: 0.7304, Acc: 66.22%

Batch 20/169 Loss: 0.4817 TS Grad: 2.9564 Img Grad: 0.3541 Ratio: 0.12
Batch 40/169 Loss: 0.5303 TS Grad: 3.2575 Img Grad: 0.3977 Ratio: 0.12
Batch 60/169 Loss: 0.4999 TS Grad: 3.3811 Img Grad: 0.2709 Ratio: 0.08
Batch 80/169 Loss: 0.5228 TS Grad: 3.8032 Img Grad: 0.2505 Ratio: 0.07
Batch 100/169 Loss: 0.4111 TS Grad: 2.3691 Img Grad: 0.1224 Ratio: 0.05
Batch 120/169 Loss: 0.5785 TS Grad: 4.2116 Img Grad: 0.2679 Ratio: 0.06
Batch 140/169 Loss: 0.6261 TS Grad: 4.7618 Img Grad: 0.3039 Ratio: 0.06
Batch 160/169 Loss: 0.5897 TS Grad: 4.4809 Img Grad: 0.4919 Ratio: 0.11

Epoch [3/30], Train Loss: 0.5549, Acc: 72.78%, Val Loss: 0.5701, Acc: 71.83%

Batch 20/169 Loss: 0.6362 TS Grad: 4.8162 Img Grad: 0.6638 Ratio: 0.14
Batch 40/169 Loss: 0.5878 TS Grad: 4.8783 Img Grad: 0.6764 Ratio: 0.14
Batch 60/169 Loss: 0.4361 TS Grad: 2.6548 Img Grad: 0.4726 Ratio: 0.18
Batch 80/169 Loss: 0.4941 TS Grad: 3.4858 Img Grad: 0.7120 Ratio: 0.20
Batch 100/169 Loss: 0.4174 TS Grad: 3.1857 Img Grad: 0.2979 Ratio: 0.09
Batch 120/169 Loss: 0.6061 TS Grad: 3.9367 Img Grad: 0.3408 Ratio: 0.09
Batch 140/169 Loss: 0.6329 TS Grad: 4.5979 Img Grad: 0.1944 Ratio: 0.04
Batch 160/169 Loss: 0.4471 TS Grad: 3.7538 Img Grad: 0.2076 Ratio: 0.06

Epoch [4/30], Train Loss: 0.5321, Acc: 73.89%, Val Loss: 0.5415, Acc: 72.83%

Batch 20/169 Loss: 0.6044 TS Grad: 5.1272 Img Grad: 0.6493 Ratio: 0.13
Batch 40/169 Loss: 0.5176 TS Grad: 5.1254 Img Grad: 0.4152 Ratio: 0.08
Batch 60/169 Loss: 0.5270 TS Grad: 4.2282 Img Grad: 0.4022 Ratio: 0.10
Batch 80/169 Loss: 0.3903 TS Grad: 3.1453 Img Grad: 0.1307 Ratio: 0.04
Batch 100/169 Loss: 0.4820 TS Grad: 4.6233 Img Grad: 0.3265 Ratio: 0.07
Batch 120/169 Loss: 0.7489 TS Grad: 5.5483 Img Grad: 0.2015 Ratio: 0.04
Batch 140/169 Loss: 0.5647 TS Grad: 4.8946 Img Grad: 0.1660 Ratio: 0.03
Batch 160/169 Loss: 0.4837 TS Grad: 3.0410 Img Grad: 0.0818 Ratio: 0.03

Epoch [5/30], Train Loss: 0.5157, Acc: 75.81%, Val Loss: 0.5360, Acc: 73.33%

Batch 20/169 Loss: 0.5649 TS Grad: 3.8669 Img Grad: 0.3854 Ratio: 0.10
Batch 40/169 Loss: 0.5683 TS Grad: 4.4047 Img Grad: 0.2113 Ratio: 0.05
Batch 60/169 Loss: 0.4910 TS Grad: 4.8427 Img Grad: 0.1799 Ratio: 0.04
Batch 80/169 Loss: 0.4921 TS Grad: 2.9257 Img Grad: 0.2187 Ratio: 0.07
Batch 100/169 Loss: 0.6876 TS Grad: 4.8042 Img Grad: 0.2654 Ratio: 0.06
Batch 120/169 Loss: 0.5413 TS Grad: 5.2222 Img Grad: 0.0826 Ratio: 0.02
Batch 140/169 Loss: 0.5490 TS Grad: 7.1610 Img Grad: 0.0432 Ratio: 0.01
Batch 160/169 Loss: 0.3673 TS Grad: 5.0113 Img Grad: 0.0782 Ratio: 0.02

Epoch [6/30], Train Loss: 0.5048, Acc: 76.85%, Val Loss: 0.5329, Acc: 74.00%

Batch 20/169 Loss: 0.5494 TS Grad: 5.1643 Img Grad: 0.0829 Ratio: 0.02
Batch 40/169 Loss: 0.4750 TS Grad: 6.8659 Img Grad: 0.0840 Ratio: 0.01
Batch 60/169 Loss: 0.4821 TS Grad: 3.6923 Img Grad: 0.1337 Ratio: 0.04
Batch 80/169 Loss: 0.4954 TS Grad: 5.7026 Img Grad: 0.0735 Ratio: 0.01
Batch 100/169 Loss: 0.4980 TS Grad: 4.5327 Img Grad: 0.0824 Ratio: 0.02
Batch 120/169 Loss: 0.5095 TS Grad: 6.2383 Img Grad: 0.6484 Ratio: 0.10
Batch 140/169 Loss: 0.3970 TS Grad: 4.2021 Img Grad: 0.1524 Ratio: 0.04
Batch 160/169 Loss: 0.5514 TS Grad: 4.8730 Img Grad: 0.0978 Ratio: 0.02

Epoch [7/30], Train Loss: 0.4933, Acc: 77.52%, Val Loss: 0.5416, Acc: 73.17%

Batch 20/169 Loss: 0.4922 TS Grad: 5.1268 Img Grad: 0.1092 Ratio: 0.02
Batch 40/169 Loss: 0.4589 TS Grad: 4.6932 Img Grad: 0.6928 Ratio: 0.15
Batch 60/169 Loss: 0.5026 TS Grad: 5.5364 Img Grad: 0.1382 Ratio: 0.02
Batch 80/169 Loss: 0.4859 TS Grad: 4.3652 Img Grad: 0.2140 Ratio: 0.05
Batch 100/169 Loss: 0.6627 TS Grad: 8.7616 Img Grad: 0.2404 Ratio: 0.03
Batch 120/169 Loss: 0.3498 TS Grad: 2.7961 Img Grad: 0.2313 Ratio: 0.08
Batch 140/169 Loss: 0.7424 TS Grad: 6.6585 Img Grad: 0.2996 Ratio: 0.04
Batch 160/169 Loss: 0.5509 TS Grad: 6.9126 Img Grad: 0.0796 Ratio: 0.01

Epoch [8/30], Train Loss: 0.4802, Acc: 78.06%, Val Loss: 0.5821, Acc: 72.44%

Batch 20/169 Loss: 0.4284 TS Grad: 4.0054 Img Grad: 0.1182 Ratio: 0.03
Batch 40/169 Loss: 0.5018 TS Grad: 6.3823 Img Grad: 0.2558 Ratio: 0.04
Batch 60/169 Loss: 0.5718 TS Grad: 9.9481 Img Grad: 0.2557 Ratio: 0.03
Batch 80/169 Loss: 0.4704 TS Grad: 4.7276 Img Grad: 0.1931 Ratio: 0.04
Batch 100/169 Loss: 0.4263 TS Grad: 3.6459 Img Grad: 0.2240 Ratio: 0.06
Batch 120/169 Loss: 0.6003 TS Grad: 5.3837 Img Grad: 0.3233 Ratio: 0.06
Batch 140/169 Loss: 0.5289 TS Grad: 8.0819 Img Grad: 0.1632 Ratio: 0.02
Batch 160/169 Loss: 0.5963 TS Grad: 7.8835 Img Grad: 0.2480 Ratio: 0.03

Epoch [9/30], Train Loss: 0.4683, Acc: 78.76%, Val Loss: 0.5395, Acc: 73.72%

Batch 20/169 Loss: 0.4159 TS Grad: 4.6805 Img Grad: 0.2070 Ratio: 0.04
Batch 40/169 Loss: 0.3833 TS Grad: 3.5624 Img Grad: 0.2190 Ratio: 0.06
Batch 60/169 Loss: 0.4175 TS Grad: 5.3754 Img Grad: 0.2142 Ratio: 0.04
Batch 80/169 Loss: 0.6006 TS Grad: 4.7135 Img Grad: 0.2936 Ratio: 0.06
Batch 100/169 Loss: 0.3647 TS Grad: 5.4440 Img Grad: 0.1631 Ratio: 0.03
Batch 120/169 Loss: 0.5468 TS Grad: 7.6908 Img Grad: 0.5524 Ratio: 0.07
Batch 140/169 Loss: 0.5092 TS Grad: 8.5755 Img Grad: 0.1600 Ratio: 0.02
Batch 160/169 Loss: 0.5394 TS Grad: 6.1257 Img Grad: 0.1227 Ratio: 0.02

Epoch [10/30], Train Loss: 0.4621, Acc: 79.94%, Val Loss: 0.5327, Acc: 74.11%

Batch 20/169 Loss: 0.4388 TS Grad: 5.2239 Img Grad: 0.3530 Ratio: 0.07
Batch 40/169 Loss: 0.3622 TS Grad: 4.3948 Img Grad: 0.2769 Ratio: 0.06
Batch 60/169 Loss: 0.5383 TS Grad: 4.8678 Img Grad: 0.3704 Ratio: 0.08
Batch 80/169 Loss: 0.5012 TS Grad: 8.2579 Img Grad: 0.6445 Ratio: 0.08
Batch 100/169 Loss: 0.5338 TS Grad: 6.4134 Img Grad: 0.5724 Ratio: 0.09
Batch 120/169 Loss: 0.6592 TS Grad: 9.8484 Img Grad: 1.6102 Ratio: 0.16
Batch 140/169 Loss: 0.3742 TS Grad: 4.8182 Img Grad: 0.2663 Ratio: 0.06
Batch 160/169 Loss: 0.4555 TS Grad: 3.9949 Img Grad: 0.3358 Ratio: 0.08

Epoch [11/30], Train Loss: 0.4531, Acc: 80.52%, Val Loss: 2.8788, Acc: 49.50%

Batch 20/169 Loss: 0.4205 TS Grad: 4.7427 Img Grad: 0.2120 Ratio: 0.04
Batch 40/169 Loss: 0.4296 TS Grad: 4.6831 Img Grad: 0.2465 Ratio: 0.05
Batch 60/169 Loss: 0.4867 TS Grad: 4.9337 Img Grad: 0.6827 Ratio: 0.14
Batch 80/169 Loss: 0.3908 TS Grad: 4.3850 Img Grad: 0.4195 Ratio: 0.10
Batch 100/169 Loss: 0.4886 TS Grad: 5.6340 Img Grad: 0.2095 Ratio: 0.04
Batch 120/169 Loss: 0.5289 TS Grad: 10.3603 Img Grad: 0.1927 Ratio: 0.02
Batch 140/169 Loss: 0.3859 TS Grad: 4.6575 Img Grad: 0.1092 Ratio: 0.02
Batch 160/169 Loss: 0.5510 TS Grad: 6.3117 Img Grad: 0.1820 Ratio: 0.03

Epoch [12/30], Train Loss: 0.4444, Acc: 81.09%, Val Loss: 0.6063, Acc: 72.39%

Batch 20/169 Loss: 0.3176 TS Grad: 3.1508 Img Grad: 0.2503 Ratio: 0.08
Batch 40/169 Loss: 0.4676 TS Grad: 6.7345 Img Grad: 0.2772 Ratio: 0.04
Batch 60/169 Loss: 0.3594 TS Grad: 6.8314 Img Grad: 0.1564 Ratio: 0.02
Batch 80/169 Loss: 0.3776 TS Grad: 5.0511 Img Grad: 0.1637 Ratio: 0.03
Batch 100/169 Loss: 0.3113 TS Grad: 3.4052 Img Grad: 0.1032 Ratio: 0.03
Batch 120/169 Loss: 0.3473 TS Grad: 3.4924 Img Grad: 0.2190 Ratio: 0.06
Batch 140/169 Loss: 0.4432 TS Grad: 6.0340 Img Grad: 0.5014 Ratio: 0.08
Batch 160/169 Loss: 0.4645 TS Grad: 5.4734 Img Grad: 0.2925 Ratio: 0.05

Epoch [13/30], Train Loss: 0.4286, Acc: 81.83%, Val Loss: 0.8986, Acc: 65.22%

Batch 20/169 Loss: 0.5277 TS Grad: 5.5011 Img Grad: 0.2524 Ratio: 0.05
Batch 40/169 Loss: 0.3386 TS Grad: 4.8902 Img Grad: 0.2560 Ratio: 0.05
Batch 60/169 Loss: 0.6375 TS Grad: 7.0680 Img Grad: 0.1677 Ratio: 0.02
Batch 80/169 Loss: 0.4366 TS Grad: 6.5626 Img Grad: 0.5158 Ratio: 0.08
Batch 100/169 Loss: 0.3954 TS Grad: 4.6294 Img Grad: 0.1587 Ratio: 0.03
Batch 120/169 Loss: 0.4065 TS Grad: 5.1042 Img Grad: 0.2646 Ratio: 0.05
Batch 140/169 Loss: 0.4259 TS Grad: 4.2600 Img Grad: 0.4168 Ratio: 0.10
Batch 160/169 Loss: 0.3033 TS Grad: 3.7156 Img Grad: 0.1681 Ratio: 0.05

Epoch [14/30], Train Loss: 0.4252, Acc: 82.02%, Val Loss: 0.5880, Acc: 71.33%

Batch 20/169 Loss: 0.4194 TS Grad: 4.8632 Img Grad: 0.5813 Ratio: 0.12
Batch 40/169 Loss: 0.3022 TS Grad: 3.6451 Img Grad: 0.3606 Ratio: 0.10
Batch 60/169 Loss: 0.4206 TS Grad: 5.3073 Img Grad: 0.3888 Ratio: 0.07
Batch 80/169 Loss: 0.3984 TS Grad: 7.2989 Img Grad: 0.2895 Ratio: 0.04
Batch 100/169 Loss: 0.3821 TS Grad: 5.3571 Img Grad: 0.3526 Ratio: 0.07
Batch 120/169 Loss: 0.3522 TS Grad: 4.2894 Img Grad: 0.1672 Ratio: 0.04
Batch 140/169 Loss: 0.4693 TS Grad: 9.8221 Img Grad: 0.4338 Ratio: 0.04
Batch 160/169 Loss: 0.2930 TS Grad: 5.3233 Img Grad: 0.1614 Ratio: 0.03

Epoch [15/30], Train Loss: 0.4233, Acc: 82.35%, Val Loss: 0.5795, Acc: 72.50%

Batch 20/169 Loss: 0.4045 TS Grad: 5.8582 Img Grad: 0.4357 Ratio: 0.07
Batch 40/169 Loss: 0.3534 TS Grad: 6.8727 Img Grad: 0.4261 Ratio: 0.06
Batch 60/169 Loss: 0.4527 TS Grad: 7.3677 Img Grad: 0.4282 Ratio: 0.06
Batch 80/169 Loss: 0.5984 TS Grad: 9.3037 Img Grad: 0.5133 Ratio: 0.06
Batch 100/169 Loss: 0.4142 TS Grad: 8.4954 Img Grad: 0.3195 Ratio: 0.04
Batch 120/169 Loss: 0.2640 TS Grad: 4.3025 Img Grad: 0.2423 Ratio: 0.06
Batch 140/169 Loss: 0.3653 TS Grad: 6.5436 Img Grad: 0.8171 Ratio: 0.12
Batch 160/169 Loss: 0.3451 TS Grad: 5.7313 Img Grad: 0.4843 Ratio: 0.08
Early stopping at epoch 16

[步骤5] 评估模型性能...
  正在加载最佳模型: best_damage_detector.pth

==================================================
测试集性能:
==================================================
准确率:   0.7228
精确率:   0.7113
召回率:   0.7118
F1分数:   0.7116

============================================================
开始进行消融实验
============================================================
模型配置                 | Loss       | Accuracy   | 贡献度       
------------------------------------------------------------
Full Model           | 0.5357     | 72.28     % | (Baseline)
Image Only           | 0.7576     | 60.06     % | (-12.22%)
Time Series Only     | 0.5322     | 72.28     % | (+0.00%)
------------------------------------------------------------
⚠ 结论: 模型性能主要依赖于时序分支，图像特征贡献较小。
============================================================

[步骤6] 保存模型...
  ✓ 模型已保存: new_simulator_trained_model.pth

======================================================================
✓ 训练完成！
======================================================================